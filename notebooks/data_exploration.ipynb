{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve().parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = PROJECT_ROOT / \"data\"\n",
    "print(type(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = data_dir / \"Louisiana-West-Test\"\n",
    "data_dir.exists() or sys.exit(f\"Data directory {data_dir} does not exist. Please check the path.\")\n",
    "test_dir.exists() or sys.exit(f\"Test directory {test_dir} does not exist. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"Germany\"\n",
    "split = \"Training\"\n",
    "data_types = [\"label_image_mapping\", \"reference\"]\n",
    "naming_dict = {'label_image_mapping': 'scenes', 'reference': 'objects'}\n",
    "dfs = {naming_dict[data_type]: pd.read_csv(data_dir / f\"{location}_{split}_Public_{data_type}.csv\") for data_type in data_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_type, df in dfs.items():\n",
    "    print(f\"Data type: {data_type}\")\n",
    "    print(f\"Number of rows: {len(df)}\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['scenes']['city'] = 'Germany'\n",
    "print(dfs['scenes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0edb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = len(dfs['scenes']['label'].unique()) == len(dfs['scenes'])\n",
    "if unique_labels:\n",
    "    print(\"All labels are unique.\")\n",
    "else:\n",
    "    print(\"There are duplicate labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61cec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2_mask = ~dfs['scenes'][\"post-event image 2\"].isna()\n",
    "print(f\"Number of rows with post-event image 2: {image2_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pre_post_images(label_image_mapping, label, images='all'):\n",
    "    row = label_image_mapping[label_image_mapping['label'] == label]\n",
    "    if images == 'all':\n",
    "        image_cols = ['pre-event image', 'post-event image 1', 'post-event image 2']\n",
    "    for col in image_cols:\n",
    "        if row[col].isna().all():\n",
    "            print(f\"No image found for {col} in label {label}.\")\n",
    "            continue\n",
    "        img = Image.open(data_dir / ('PRE-event' if col=='pre-event image' else 'POST-event') / row[col].values[0])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789607de",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pre_post_images(dfs['scenes'], '0_41_59.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafa913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any post image names are used as imageIds in reference table\n",
    "items_in_ref = []\n",
    "for col in ['post-event image 1', 'post-event image 2']:\n",
    "    for item in dfs['scenes'][col].dropna():\n",
    "        if item.split('.')[0] in dfs['objects']['ImageId'].values:\n",
    "            items_in_ref.append(item)\n",
    "            print(f\"Image {item} from {col} found in reference table.\")\n",
    "if len(items_in_ref) == 0:\n",
    "    print(\"No post image items found in reference table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2550dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets counts of geometry types in WKT column of reference table\n",
    "\n",
    "def get_geotype(wkt):\n",
    "    if 'POLYGON' in wkt:\n",
    "        return 'Polygon'\n",
    "    elif 'LINESTRING' in wkt:\n",
    "        return 'LineString'\n",
    "    elif 'POINT' in wkt:\n",
    "        return 'Point'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "def convert_to_image(img):\n",
    "    if img.shape[0] == 3:\n",
    "        img = img.transpose((1, 2, 0))\n",
    "    return img\n",
    "\n",
    "def view_image(img, ax=None):\n",
    "    if ax is None:\n",
    "        old_ax = None\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        ax = fig.add_subplot(111)\n",
    "    else:\n",
    "        old_ax = ax\n",
    "    img = convert_to_image(img)\n",
    "    ax.imshow(img)\n",
    "    if old_ax is None:\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return ax\n",
    " \n",
    "def get_geoms(reference, ImageId):\n",
    "    \"\"\"\n",
    "    Get geometries for a specific image.\n",
    "    \"\"\"\n",
    "    image_mask = reference['ImageId'] == ImageId\n",
    "    geoms = reference[image_mask]['Wkt_Pix'].apply(wkt.loads)\n",
    "    lines = geoms[geoms.apply(lambda x: x.geom_type == 'LineString')]\n",
    "    polys = geoms[geoms.apply(lambda x: x.geom_type == 'Polygon')]\n",
    "    return lines, polys\n",
    "\n",
    "def get_image(regions, label, img_type='pre-event image', city='Germany', verbose=True, data_dir=data_dir, Id_only=False):\n",
    "    row = regions[regions['label'] == label]\n",
    "    if row.empty or row[img_type].isna().all():\n",
    "        if verbose:\n",
    "            print(f\"No {img_type} found for label {label}.\")\n",
    "        return None\n",
    "    else:\n",
    "        #Ids are just the pre-event image names without the .tif extension\n",
    "        if Id_only:\n",
    "            return row['pre-event image'].values[0].split('.tif')[0]\n",
    "        else:\n",
    "            img_path = data_dir / f'{city}_Training' / ('PRE-event' if img_type == 'pre-event image' else 'POST-event') / row[img_type].values[0]\n",
    "            img = tiff.imread(img_path)\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_geometries(label_image_mapping, reference, label, flag_idx=None):\n",
    "    row = label_image_mapping[label_image_mapping['label'] == label]\n",
    "\n",
    "    #get image Id\n",
    "    ImageId = get_image(row, label, Id_only=True)\n",
    "    if ImageId is None:\n",
    "        return\n",
    "    \n",
    "    image_types = ['pre-event image', 'post-event image 1', 'post-event image 2']\n",
    "    for img_type in image_types:\n",
    "        if img_type != 'pre-event image' and row[img_type].isna().all():\n",
    "            print(f\"No image found for {img_type} in label {label}.\")\n",
    "            continue\n",
    "\n",
    "        #get lines and polygons for this image\n",
    "        lines, polys = get_geoms(reference, ImageId)\n",
    "\n",
    "        #load image\n",
    "        img = get_image(row, label, img_type=img_type)\n",
    "\n",
    "        flag_mask = np.ones_like(lines, dtype=bool)\n",
    "\n",
    "        print(f\"Showing {img_type} for label {label}.\")\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax = view_image(img, ax=ax)\n",
    "        if flag_idx is not None:\n",
    "            flag_mask[flag_idx] = False\n",
    "            # print pixels of flagged geometries\n",
    "            print(f\"Flagged geometries: {lines.iloc[flag_idx]}\")\n",
    "            gdf_flag = gpd.GeoDataFrame(geometry=lines[~flag_mask])\n",
    "            gdf_flag.plot(ax=ax, facecolor='none', edgecolor='purple')\n",
    "\n",
    "        gdf_lines = gpd.GeoDataFrame(geometry=lines[flag_mask])\n",
    "        gdf_polys = gpd.GeoDataFrame(geometry=polys)\n",
    "    \n",
    "        gdf_lines.plot(ax=ax, facecolor='none', edgecolor='red')\n",
    "        gdf_polys.plot(ax=ax, facecolor='blue', edgecolor='blue', alpha = 0.7)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Extract objects in a certain image'''\n",
    "#------------------------------------------\n",
    "label = '0_41_58.geojson'\n",
    "#------------------------------------------\n",
    "which_image = 'pre-event image' #must be pre-event image, references are only linked to pre-event images\n",
    "ImageId = dfs['scenes'][which_image][dfs['scenes']['label'] == label].values[0].split('.tif')[0]\n",
    "image_mask = dfs['objects']['ImageId'] == ImageId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = dfs['objects'][image_mask]['Wkt_Pix'].apply(wkt.loads)\n",
    "lines = shapes[shapes.apply(lambda x: x.geom_type == 'LineString')]\n",
    "line_lengths = lines.apply(lambda geom: geom.coords).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329893c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 20\n",
    "plot_image_with_geometries(dfs['scenes'], dfs['objects'], '0_41_59.geojson', flag_idx=idx)\n",
    "assert shapes.iloc[idx].geom_type == 'LineString', f'{shapes.iloc[idx].geom_type} object is not subscriptable'\n",
    "point = shapes.iloc[idx].coords[0]\n",
    "print(point)\n",
    "print('number of segments with same point:', shapes.apply(lambda x: point in list(x.coords) if x.geom_type == 'LineString' else False).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs['objects']['Wkt_Pix'].apply(get_geotype).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a8862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot images with overlaid geometries from reference table\n",
    "plot_image_with_geometries(dfs['scenes'], dfs['objects'], '0_26_62.geojson', flag_idx=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect pre and post images\n",
    "#label = '0_41_59.geojson'\n",
    "image_types = ['pre-event image', 'post-event image 1', 'post-event image 2']\n",
    "arrs = []\n",
    "for img_type in image_types:\n",
    "    for label in dfs['scenes']['label'].unique():\n",
    "        row = dfs['scenes'][dfs['scenes']['label'] == label]\n",
    "        if row.empty or row[img_type].isna().all():\n",
    "            print(f\"No {img_type} found for label {label}.\")\n",
    "            continue\n",
    "        img_path = data_dir / ('PRE-event' if img_type == 'pre-event image' else 'POST-event') / row[img_type].values[0]\n",
    "        img = tiff.imread(img_path)\n",
    "        print(f'shape of {img_type} for label {label}: ', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample post-event images\n",
    "import cv2\n",
    "num_pix = 1300\n",
    "img = arrs[-1]\n",
    "out = cv2.resize(\n",
    "        img, \n",
    "        (num_pix, num_pix),\n",
    "        interpolation=cv2.INTER_LANCZOS4  # Lanczos with 8-tap window\n",
    "    )\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(out)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673852f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag labels with non-square post-event images\n",
    "for label in dfs['scenes']['label'].unique():\n",
    "    row = dfs['scenes'][dfs['scenes']['label'] == label]\n",
    "    if row.empty or row['post-event image 1'].isna().all():\n",
    "        print(f\"No post-event image 1 found for label {label}.\")\n",
    "        continue\n",
    "    img_path = data_dir / 'POST-event' / row['post-event image 1'].values[0]\n",
    "    img = tiff.imread(img_path)\n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        print(f\"Label {label} has non-square post-event image 1: {img.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfa797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for non-square post-event images\n",
    "image_types = ['post-event image 1', 'post-event image 2']\n",
    "for label in dfs['scenes']['label'].unique():\n",
    "    mismatch = False\n",
    "    imgs = []\n",
    "    for image_type in image_types:\n",
    "        img = get_image(dfs['scenes'], label, img_type=image_type, verbose=False)\n",
    "        imgs.append(img)\n",
    "        if img is not None:\n",
    "            if abs(img.shape[0] - img.shape[1]) > 1:\n",
    "                mismatch = True\n",
    "    if mismatch:\n",
    "        pre_img = get_image(dfs['scenes'], label, img_type='pre-event image', verbose=False)\n",
    "        print(f\"Label {label} has non-square post-event images\")\n",
    "        # display pre-image and dimensions\n",
    "        ax = view_image(pre_img)\n",
    "        ax.set_title(f\"pre-event image shape: {pre_img.shape}\")\n",
    "        print(f\"pre-event image for label {label} shape: {pre_img.shape}\")\n",
    "        for img, image_type in zip(imgs, image_types):\n",
    "            if img is not None:\n",
    "                fig = plt.figure(figsize=(6, 6))\n",
    "                ax = view_image(img)\n",
    "                ax.set_title(f\"{image_type} shape: {img.shape}\")\n",
    "                print(f\"{image_type} for label {label} shape: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a64994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rootSIFT(D, eps=1e-12):\n",
    "    D = D / (np.sum(D, axis=1, keepdims=True) + eps)\n",
    "    D = np.sqrt(D)\n",
    "    return D\n",
    "\n",
    "def scale_filtered_pairs(kp1, kp2, match, max_ratio=1.5, min_px=None, max_px=None): \n",
    "    s1 = kp1[match.queryIdx].size\n",
    "    s2 = kp2[match.trainIdx].size\n",
    "    if min_px and (s1 < min_px or s2 < min_px): \n",
    "        return False\n",
    "    if max_px and (s1 > max_px or s2 > max_px): \n",
    "        return False\n",
    "    r = max(s1, s2) / max(1e-6, min(s1, s2))\n",
    "    if r <= max_ratio:                 # e.g., allow ≤ 1.5× scale difference\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def sift_matches(imgA, imgB, ratio=0.7):\n",
    "    sift = cv2.SIFT_create(\n",
    "        nOctaveLayers=4,          # keep near-edge features\n",
    "        sigma=1.2\n",
    "    )\n",
    "\n",
    "    kA, dA = sift.detectAndCompute(imgA, None)\n",
    "    kB, dB = sift.detectAndCompute(imgB, None)\n",
    "    #dA = rootSIFT(dA)\n",
    "    #dB = rootSIFT(dB)\n",
    "   \n",
    "    index_params = dict(algorithm=1, trees=5)\n",
    "    search_params = dict(checks=100)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    #matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    knn = bf.knnMatch(dA, dB, k=2)\n",
    "    print(len(knn), \"matches found\")\n",
    "    good = []\n",
    "    #only keep matches that are large enough \n",
    "\n",
    "    for m, n in knn:\n",
    "        if not scale_filtered_pairs(kA, kB, m, max_ratio=1.5, min_px=10, max_px=None):\n",
    "            continue\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append((m.queryIdx, m.trainIdx, m.distance))\n",
    "\n",
    "    if len(good) < 3:\n",
    "        raise RuntimeError(\"Not enough matches after ratio test\")\n",
    "\n",
    "    ptsA = np.float32([kA[i].pt for i, _, _ in good])\n",
    "    ptsB = np.float32([kB[j].pt for _, j, _ in good])\n",
    "    szA = np.array([kA[i].size for i, _, _ in good])\n",
    "    szB = np.array([kB[j].size for _, j, _ in good])\n",
    "    distances = [d for _, _, d in good]\n",
    "    return ptsA, ptsB, distances, szA, szB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pre = get_image(dfs['scenes'], '0_40_59.geojson', img_type='pre-event image', verbose=True)\n",
    "img_post = get_image(dfs['scenes'], '0_40_59.geojson', img_type='post-event image 1', verbose=True)\n",
    "\n",
    "#pre event image\n",
    "print(f\"pre-event image shape: {img_pre.shape}\")\n",
    "view_image(img_pre)\n",
    "\n",
    "#post event image\n",
    "print(f\"post-event image shape: {img_post.shape}\")\n",
    "view_image(img_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26624d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img_pre[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Resize function to maintain aspect ratio and use appropriate interpolation based on size\n",
    "ref_size: tuple of (width, height) to resize the image to\n",
    "'''\n",
    "def resize(img, ref_size=(1300, 1300), padding='top'):\n",
    "    if img.shape[0] == 3:\n",
    "        img = img.transpose((1, 2, 0))\n",
    "    if ref_size[0] > img.shape[1]:\n",
    "        interp = cv2.INTER_LANCZOS4\n",
    "    else:\n",
    "        interp = cv2.INTER_AREA\n",
    "    new_size = (ref_size[0], int(ref_size[0] * img.shape[0] / img.shape[1])) # (W, H)\n",
    "    scaled_img = cv2.resize(img, new_size, interpolation=interp)\n",
    "    if img.shape[0] == img.shape[1]:\n",
    "        padded_img = scaled_img\n",
    "    else:   \n",
    "        if padding == 'top':\n",
    "            padded_img = cv2.copyMakeBorder(scaled_img, max(0, ref_size[1] - new_size[1]), 0, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        elif padding == 'bottom':\n",
    "            padded_img = cv2.copyMakeBorder(scaled_img, 0, max(0, ref_size[1] - new_size[1]), 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        else:\n",
    "            padded_img = scaled_img\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "def align_w_pre(img_post, img_pre, clahe=False):\n",
    "    ref_size = img_pre.shape[:2]\n",
    "    img_post = resize(img_post, ref_size=(1300, 1300), padding='top')\n",
    "\n",
    "    # convert to grayscale (required for ECC)\n",
    "    gray_post = cv2.cvtColor(convert_to_image(img_post), cv2.COLOR_BGR2GRAY)\n",
    "    gray_pre = cv2.cvtColor(convert_to_image(img_pre), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if clahe:\n",
    "        clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(16, 16))\n",
    "        gray_pre = clahe.apply(gray_pre)\n",
    "        gray_post = clahe.apply(gray_post)\n",
    "    # template = reference, input = to be warped\n",
    "    template = gray_pre\n",
    "    input_img = gray_post\n",
    "\n",
    "    # initial warp matrix for translation = 2x3 identity\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # define the stopping criteria\n",
    "    criteria = (\n",
    "        cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,\n",
    "        10000,    # max iterations\n",
    "        1e-6     # convergence threshold\n",
    "    )\n",
    "\n",
    "    # run ECC\n",
    "    cc, warp_matrix = cv2.findTransformECC(\n",
    "        template,\n",
    "        input_img,\n",
    "        warp_matrix,\n",
    "        motionType=cv2.MOTION_TRANSLATION,\n",
    "        criteria=criteria\n",
    "    )\n",
    "\n",
    "    print(\"Correlation coefficient:\", cc)\n",
    "    print(\"Warp matrix:\\n\", warp_matrix)\n",
    "\n",
    "    # apply the translation\n",
    "    h, w = template.shape\n",
    "    aligned = cv2.warpAffine(img_post, warp_matrix, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1300\n",
    "start_x, start_y = 0, 0\n",
    "img_pre.shape\n",
    "view_image(img_pre[:, start_y:start_y+size, start_x:start_x+size])\n",
    "view_image(aligned[start_y:start_y+size, start_x:start_x+size, :])\n",
    "view_image(img_post[start_y:start_y+size, start_x:start_x+size, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pix = 1300\n",
    "img_post = cv2.resize(\n",
    "        img_post, \n",
    "        (num_pix, num_pix),\n",
    "        interpolation=cv2.INTER_LANCZOS4  # Lanczos with 8-tap window\n",
    ")\n",
    "gray_pre = cv2.cvtColor(convert_to_image(img_pre), cv2.COLOR_BGR2GRAY)\n",
    "gray_post = cv2.cvtColor(convert_to_image(img_post), cv2.COLOR_BGR2GRAY)\n",
    "clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(16, 16))\n",
    "#gray_pre = clahe.apply(gray_pre)\n",
    "#gray_post = clahe.apply(gray_post)\n",
    "print(gray_pre.shape)\n",
    "#view_image(gray_pre)\n",
    "#view_image(gray_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_post, pts_pre, distances, sz_post, sz_pre = sift_matches(gray_post, gray_pre, ratio=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6855a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pts = pts_post.shape[0]\n",
    "print(f\"Number of matched points retained: {num_pts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = num_pts\n",
    "print(f'Top {max_idx} matches:')\n",
    "#for idx in range(max_idx):\n",
    "    #print(f\"Match {idx}: diff {pts_post[idx, :]-pts_pre[idx, :]} post {pts_post[idx, :]} pre {pts_pre[idx, :]} distance {distances[idx]} size_post {sz_post[idx]} size_pre {sz_pre[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check matches\n",
    "pts_post_rescaled = pts_post*(1300/gray_post.shape[0])\n",
    "pts_pre_rescaled = pts_pre*(1300/gray_pre.shape[0])\n",
    "max_idx = num_pts\n",
    "#print(f'Top {max_idx} matches:')\n",
    "#for idx in range(max_idx):\n",
    "    #print(f\"Match {idx}: post {pts_post_rescaled[idx, :]} pre {pts_pre_rescaled[idx, :]} distance {distances[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a553899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1663f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_img = get_image(dfs['scenes'], '0_27_62.geojson', img_type='pre-event image', verbose=True)\n",
    "view_image(pre_img)\n",
    "post_img = get_image(dfs['scenes'], '0_27_62.geojson', img_type='post-event image 1', verbose=True)\n",
    "view_image(post_img)\n",
    "post_img2 = get_image(dfs['scenes'], '0_27_62.geojson', img_type='post-event image 2', verbose=True)\n",
    "if post_img2 is not None:   \n",
    "    view_image(post_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98baeb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_img = resize(post_img, ref_size=(1300, 1300))\n",
    "post_img2 = resize(post_img2, ref_size=(1300, 1300)) if post_img2 is not None else None\n",
    "view_image(pre_img)\n",
    "view_image(post_img)\n",
    "if post_img2 is not None:\n",
    "    view_image(post_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(post_img.shape)\n",
    "print(post_img2.shape if post_img2 is not None else \"No second post-event image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_segment_distance(px, py, x0, y0, x1, y1):\n",
    "    # vectorized distance from grid points (px,py) to segment (x0,y0)-(x1,y1)\n",
    "    vx, vy = x1 - x0, y1 - y0\n",
    "    wx, wy = px - x0, py - y0\n",
    "    vv = vx*vx + vy*vy + 1e-12\n",
    "    t = (wx*vx + wy*vy) / vv\n",
    "    t = np.clip(t, 0.0, 1.0)\n",
    "    projx, projy = x0 + t*vx, y0 + t*vy\n",
    "    dx, dy = px - projx, py - projy\n",
    "    return np.sqrt(dx*dx + dy*dy), t  # return t if you want d_parallel too\n",
    "\n",
    "# D: stack of per-segment distances, shape [n_segments, H, W], all >= 0\n",
    "# tau: softness (pixels), e.g., 0.5–1.0\n",
    "def softmin_distance(D, tau, eps=1e-12):\n",
    "    \"\"\"\n",
    "    D: [n, H, W] unsquared distances; may contain +inf\n",
    "    tau: softness (pixels)\n",
    "    returns: d_soft [H, W] with +inf where no finite distances exist\n",
    "    \"\"\"\n",
    "    finite_mask = np.isfinite(D)             # [n,H,W]\n",
    "    has_finite  = finite_mask.any(axis=0)    # [H,W]\n",
    "\n",
    "    # Per-pixel min over finite entries; inf if none\n",
    "    D_masked = np.where(finite_mask, D, np.inf)\n",
    "    m = D_masked.min(axis=0)                 # [H,W], inf where !has_finite\n",
    "\n",
    "    # shifted = (D - m) / tau only where finite\n",
    "    shifted = np.empty_like(D)\n",
    "    np.subtract(D, m[None, ...], out=shifted, where=finite_mask)     # no inf-inf\n",
    "    np.divide(shifted, max(tau, eps), out=shifted, where=finite_mask)\n",
    "\n",
    "    # S = sum exp(-shifted) over finite entries only\n",
    "    exp_term = np.zeros_like(D, dtype=D.dtype)\n",
    "    np.exp(-shifted, out=exp_term, where=finite_mask)\n",
    "    S = exp_term.sum(axis=0)                                        # [H,W]\n",
    "    S = np.where(has_finite, S, 0.0)\n",
    "\n",
    "    # d_soft = m - tau * log(S) where finite; else +inf\n",
    "    d_soft = np.where(has_finite, m - tau * np.log(S + eps), np.inf)\n",
    "\n",
    "    # Optional: clamp tiny negatives from fp errors\n",
    "    d_soft = np.where(np.isfinite(d_soft), np.maximum(d_soft, 0.0), d_soft)\n",
    "    return d_soft\n",
    "\n",
    "def soft_or_centerlines(H, W, segments, sigma_perp, sigma_para=None):\n",
    "    # segments: Series of linestring objects with two points ((x0,y0),(x1,y1)) in pixel coords (float)\n",
    "    Y_log = np.zeros((H, W), dtype=np.float32)  # will accumulate log(1 - g_i)\n",
    "    Y_log[:] = 0.0  # since log(1) = 0; we will add log(1 - g_i)\n",
    "\n",
    "    three_sigma = 3.0 * sigma_perp\n",
    "    for segment in segments:\n",
    "        (x0,y0),(x1,y1) = segment.coords\n",
    "        # ROI bounds padded by ~3σ⊥\n",
    "        xmin = int(max(0, np.floor(min(x0,x1) - three_sigma)))\n",
    "        xmax = int(min(W-1, np.ceil (max(x0,x1) + three_sigma)))\n",
    "        ymin = int(max(0, np.floor(min(y0,y1) - three_sigma)))\n",
    "        ymax = int(min(H-1, np.ceil (max(y0,y1) + three_sigma)))\n",
    "        if xmin > xmax or ymin > ymax: \n",
    "            continue\n",
    "\n",
    "        xs = np.arange(xmin, xmax+1, dtype=np.float32)\n",
    "        ys = np.arange(ymin, ymax+1, dtype=np.float32)\n",
    "        px, py = np.meshgrid(xs, ys)  # shape [roi_h, roi_w]\n",
    "\n",
    "        d_perp, t = point_to_segment_distance(px, py, x0, y0, x1, y1)\n",
    "\n",
    "        if sigma_para is None:  # perpendicular-only kernel\n",
    "            g = np.exp(-0.5 * (d_perp / sigma_perp)**2)\n",
    "        else:\n",
    "            # compute parallel distance for anisotropic kernel\n",
    "            # segment direction (unit)\n",
    "            vx, vy = x1 - x0, y1 - y0\n",
    "            seg_len = np.sqrt(vx*vx + vy*vy) + 1e-12\n",
    "            ux, uy = vx/seg_len, vy/seg_len\n",
    "            # vector from projection to point: (dx,dy) = (px - projx, py - projy)\n",
    "            projx, projy = x0 + t*vx, y0 + t*vy\n",
    "            dx, dy = px - projx, py - projy\n",
    "            d_para = dx*ux + dy*uy\n",
    "            g = np.exp(-0.5 * (d_perp / sigma_perp)**2 - 0.5 * (d_para / sigma_para)**2)\n",
    "\n",
    "        g = np.clip(g, 0.0, 1.0 - 1e-7)  # avoid log(0)\n",
    "        Y_log[ymin:ymax+1, xmin:xmax+1] += np.log1p(-g)  # log(1 - g)\n",
    "\n",
    "    Y = 1.0 - np.exp(Y_log)  # since log(1 - Y) = sum log(1 - g_i)\n",
    "    return np.clip(Y, 0.0, 1.0)\n",
    "\n",
    "    # given: list of segments and a function point_to_segment_distance(px,py, ...)\n",
    "\n",
    "def softmin_gauss_centerlines_old(H, W, segments, tau=10, sigma=3):\n",
    "    D = []  \n",
    "    d_full = np.full((H, W), np.inf) # baseline distance map, all inf\n",
    "    num_segments = len(segments)   \n",
    "    for i, segment in enumerate(segments):\n",
    "        print(f\"Processing segment {i+1}/{num_segments}\")\n",
    "        (x0,y0),(x1,y1) = segment.coords\n",
    "        # ROI padding ~ 3*tau (or 3*sqrt(tau) for squared version)\n",
    "        pad = 200\n",
    "        xmin = int(max(0, np.floor(min(x0,x1) - pad)))\n",
    "        xmax = int(min(W-1, np.ceil (max(x0,x1) + pad)))\n",
    "        ymin = int(max(0, np.floor(min(y0,y1) - pad)))\n",
    "        ymax = int(min(H-1, np.ceil (max(y0,y1) + pad)))\n",
    "        if xmin>xmax or ymin>ymax: \n",
    "            continue\n",
    "\n",
    "        xs = np.arange(xmin, xmax+1, dtype=np.float32)\n",
    "        ys = np.arange(ymin, ymax+1, dtype=np.float32)\n",
    "        px, py = np.meshgrid(xs, ys)\n",
    "\n",
    "        d, _ = point_to_segment_distance(px, py, x0, y0, x1, y1)\n",
    "        d_full[ymin:ymax+1, xmin:xmax+1] = d\n",
    "        D.append(np.copy(d_full))\n",
    "        d_full = np.full((H, W), np.inf) # reset for next segment\n",
    "    # soft-min distance\n",
    "    D = np.stack(D, axis=0)  # [n_segments, H, W]\n",
    "    d_soft = softmin_distance(D, tau)\n",
    "\n",
    "    #return gaussian of the soft-min distance\n",
    "    return np.exp(-(d_soft**2) / (2 * sigma**2))\n",
    "\n",
    "def softmin_gauss_centerlines(H, W, segments, sigma=5, gamma=2, eps=1e-16, pad=200): \n",
    "    d_inv = np.zeros((H, W)) # baseline inverse distance map, all zeros\n",
    "    num_segments = len(segments)\n",
    "    for i, segment in enumerate(segments):\n",
    "        print(f\"Processing segment {i+1}/{num_segments}\")\n",
    "        (x0,y0),(x1,y1) = segment.coords\n",
    "        xmin = int(max(0, np.floor(min(x0,x1) - pad)))\n",
    "        xmax = int(min(W-1, np.ceil (max(x0,x1) + pad)))\n",
    "        ymin = int(max(0, np.floor(min(y0,y1) - pad)))\n",
    "        ymax = int(min(H-1, np.ceil (max(y0,y1) + pad)))\n",
    "        if xmin>xmax or ymin>ymax: \n",
    "            continue\n",
    "\n",
    "        xs = np.arange(xmin, xmax+1)\n",
    "        ys = np.arange(ymin, ymax+1)\n",
    "        px, py = np.meshgrid(xs, ys)\n",
    "\n",
    "        d, _ = point_to_segment_distance(px, py, x0, y0, x1, y1)\n",
    "        d_inv[ymin:ymax+1, xmin:xmax+1] += (d+eps)**(-gamma)\n",
    "    zeros_mask = d_inv!=0\n",
    "    d_soft = zeros_mask*(d_inv+eps**2)**(-1/gamma) - eps  # avoid division by zero\n",
    "    d_soft[~zeros_mask] = np.inf\n",
    "    #return gaussian of the soft-min distance\n",
    "    return np.exp(-(d_soft**2) / (2 * sigma**2))\n",
    "\n",
    "def gauss_centerlines(H, W, segments, sigma=5, eps=1e-16, pad=200): \n",
    "    d_min = np.full((H, W), np.inf) # baseline inverse distance map, all inf\n",
    "    num_segments = len(segments)\n",
    "    for i, segment in enumerate(segments):\n",
    "        print(f\"Processing segment {i+1}/{num_segments}\")\n",
    "        (x0,y0),(x1,y1) = segment.coords\n",
    "        xmin = int(max(0, np.floor(min(x0,x1) - pad)))\n",
    "        xmax = int(min(W-1, np.ceil (max(x0,x1) + pad)))\n",
    "        ymin = int(max(0, np.floor(min(y0,y1) - pad)))\n",
    "        ymax = int(min(H-1, np.ceil (max(y0,y1) + pad)))\n",
    "        if xmin>xmax or ymin>ymax: \n",
    "            continue\n",
    "\n",
    "        xs = np.arange(xmin, xmax+1)\n",
    "        ys = np.arange(ymin, ymax+1)\n",
    "        px, py = np.meshgrid(xs, ys)\n",
    "\n",
    "        d, _ = point_to_segment_distance(px, py, x0, y0, x1, y1)\n",
    "        d_min[ymin:ymax+1, xmin:xmax+1] = np.minimum(d_min[ymin:ymax+1, xmin:xmax+1], d)\n",
    "\n",
    "    #return gaussian of the min distance\n",
    "    return np.exp(-(d_min**2) / (2 * sigma**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216f09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1533b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert roads to grayscale\n",
    "label = '0_41_59.geojson'\n",
    "\n",
    "ImageId = get_image(dfs['scenes'], label, Id_only=True)\n",
    "roads, buildings = get_geoms(dfs['objects'], ImageId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe197bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#road_target = softmin_gauss_centerlines(1300, 1300, roads, sigma=10, gamma=10)\n",
    "road_target = gauss_centerlines(1300, 1300, roads, sigma=10)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "view_image(road_target, ax=ax)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(road_target), np.min(road_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19450f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(get_image(dfs['scenes'], label, img_type='pre-event image', verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09cb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileSampler:\n",
    "    #assumes image and tiles are square and accepts only single integers for sizes\n",
    "    def __init__(self, img_size, core_size, halo_size, stride):\n",
    "        self.img_size = img_size\n",
    "        self.core_size = core_size\n",
    "        self.halo_size = halo_size\n",
    "        self.stride = stride\n",
    "        # sample grid jitter\n",
    "        self.ux = np.random.randint(0, self.stride)\n",
    "        self.uy = np.random.randint(0, self.stride)\n",
    "        #number of gridlines for this arrangemnt\n",
    "        self.num_grid_x = -(-(self.img_size - self.ux) // self.stride)\n",
    "        self.num_grid_y = -(-(self.img_size - self.uy) // self.stride)\n",
    "        self.used_tiles = []  # to keep track of used tiles\n",
    "\n",
    "    def sample_tile_coords(self):\n",
    "        #sample anchor pixel\n",
    "        px, py = np.random.randint(0, self.img_size, size=(2,))\n",
    "        #check if pixel is within a stride of any edge\n",
    "        top, bottom = py < self.stride, py >= self.img_size - self.stride\n",
    "        left, right = px<self.stride, px>=self.img_size-self.stride\n",
    "        #which tile does this pixel belong to?\n",
    "        #tile num 0 is the tile belonging to the first full stride\n",
    "        #tile num self.num_grid_(x,y)-1 is the tile belonging to the last fractional stride\n",
    "        num_x = (px - self.ux) // self.stride\n",
    "        num_y = (py - self.uy) // self.stride\n",
    "        #if pixel belongs to an edge tile whose stride overlaps the next tile, sample between the two\n",
    "        if left and num_x==0:\n",
    "            num_x = np.random.randint(-1, 1)\n",
    "        elif right and num_x == self.num_grid_x - 2:\n",
    "            num_x = np.random.randint(self.num_grid_x - 2, self.num_grid_x)\n",
    "        if top and num_y==0:\n",
    "            num_y = np.random.randint(-1, 1)\n",
    "        elif bottom and num_y == self.num_grid_y - 2:\n",
    "            num_y = np.random.randint(self.num_grid_y - 2, self.num_grid_y)\n",
    "        #check if tile was used already\n",
    "        if (num_x, num_y) in self.used_tiles:\n",
    "            return self.sample_tile_coords()  # recursively sample until unused tile is found\n",
    "        #calculate tile coordinates\n",
    "        if num_x == -1:\n",
    "            x0 = 0\n",
    "        elif num_x == self.num_grid_x - 1:\n",
    "            x0 = self.img_size - self.core_size\n",
    "        else:\n",
    "            x0 = num_x * self.stride + self.ux\n",
    "        #same for y\n",
    "        if num_y == -1:\n",
    "            y0 = 0\n",
    "        elif num_y == self.num_grid_y - 1:\n",
    "            y0 = self.img_size - self.core_size\n",
    "        else:\n",
    "            y0 = num_y * self.stride + self.uy\n",
    "        \n",
    "        #store used tile coordinates\n",
    "        self.used_tiles.append((num_x, num_y))\n",
    "        return (x0, y0)\n",
    "        \n",
    "    def get_tiles(self):\n",
    "        tiles = []\n",
    "        for y in range(0, self.image.shape[0], self.tile_size):\n",
    "            for x in range(0, self.image.shape[1], self.tile_size):\n",
    "                tiles.append(self.get_tile(x, y))\n",
    "        return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73511b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TileSampler(1300, 512, 32, 256)\n",
    "for _ in range(10):\n",
    "    print(sampler.sample_tile_coords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84909167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
